{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import pickle as p\n",
    "import torch\n",
    "from tqdm.notebook import trange\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import ConvNet\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import SleepDataset\n",
    "from meanAveragePrecision import computeMeanAveragePrecision\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for training and evaluation\n",
    "def test(model, test_dataloader):\n",
    "    accuracies = []\n",
    "    f1s = []\n",
    "    softmax_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        running_accuracy = 0.0\n",
    "        conf_mat = torch.zeros(5,5)\n",
    "\n",
    "        for input, target in test_dataloader:\n",
    "            \n",
    "            output = model(input)\n",
    "\n",
    "            prediction = torch.argmax(output, dim=1).float() \n",
    "            softmax = torch.softmax(output, dim=1)\n",
    " \n",
    "            for o, t in zip(prediction, target):\n",
    "                if o == t:\n",
    "                    running_accuracy+=1/(len(test_dataloader)*batch_size)\n",
    "                \n",
    "            #running_f1 += f1_score(target, prediction)\n",
    "            conf_mat += utils.confusion_mat(output, target)\n",
    "\n",
    "            #running_f1 /= len(val_dataloader)\n",
    "\n",
    "            accuracies.append(running_accuracy)\n",
    "            #f1_val.append(running_f1)\n",
    "            softmax_scores.append(softmax.tolist())\n",
    "\n",
    "            # output\n",
    "            if (len(accuracies) % 20 == 0 or len(accuracies) == len(test_dataloader)):\n",
    "                tqdm.write('No. {} (test) -- acc: {:.4f}'.format(len(accuracies), running_accuracy))\n",
    "\n",
    "        # mean average precision\n",
    "        softmax_scores = np.asarray(softmax_scores).squeeze(1)\n",
    "        mean_avg_precision, _ = computeMeanAveragePrecision(labels, softmax_scores)\n",
    "\n",
    "        # f1 score\n",
    "        f1 = utils.f1_score(conf_mat)\n",
    "\n",
    "\n",
    "        # print last value of metrics\n",
    "        tqdm.write('Final accuracy: {:.4f}, mean avg precision {:.4f}, f1: {:.4f}'.format(running_accuracy, mean_avg_precision, f1))\n",
    "\n",
    "\n",
    "    # make metrics callable outside this function\n",
    "    test.accuracy = accuracies\n",
    "    test.f1 = f1\n",
    "    test.mean_avg_precision = mean_avg_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6364, 11, 300)\n",
      "(6364,)\n"
     ]
    }
   ],
   "source": [
    "# load data and label files\n",
    "# shape = [2284, 200, 3, 9] --> [datasets, time series, channels, devices]\n",
    "data_aug = p.load(open(r\"data_aug.pkl\", \"rb\"))\n",
    "labels = p.load(open(r\"labels_aug.pkl\", \"rb\"))\n",
    "print(data_aug.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "#reshape data into datasets x (channels x devices) x time series \n",
    "#data_aug = data_aug.transpose((0,1,3,2))\n",
    "#data = data.reshape(data.shape[0], -1, data.shape[3])\n",
    "#print(data.shape)'\n",
    "\n",
    "batch_size = 1\n",
    "# create datasets\n",
    "test_dataset = SleepDataset(data_aug[:1090,...], labels[:1090,...], train=False)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No augmentation, no weighted loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 20 (test) -- acc: 0.0138\n",
      "No. 40 (test) -- acc: 0.0367\n",
      "No. 60 (test) -- acc: 0.0596\n",
      "No. 80 (test) -- acc: 0.0734\n",
      "No. 100 (test) -- acc: 0.1101\n",
      "No. 120 (test) -- acc: 0.1422\n",
      "No. 140 (test) -- acc: 0.1560\n",
      "No. 160 (test) -- acc: 0.1743\n",
      "No. 180 (test) -- acc: 0.1927\n",
      "No. 200 (test) -- acc: 0.2248\n",
      "No. 218 (test) -- acc: 0.2477\n",
      "Final accuracy: 0.2477, mean avg precision 0.2167, f1: 0.1833\n"
     ]
    }
   ],
   "source": [
    "# load model for testing\n",
    "model = ConvNet()\n",
    "model.load_state_dict(torch.load(\"trained_models/net.pt\"))\n",
    "# test model\n",
    "test(model.double(), test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No augmentation, weighted loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 20 (test) -- acc: 0.0229\n",
      "No. 40 (test) -- acc: 0.0413\n",
      "No. 60 (test) -- acc: 0.0596\n",
      "No. 80 (test) -- acc: 0.1009\n",
      "No. 100 (test) -- acc: 0.1422\n",
      "No. 120 (test) -- acc: 0.1835\n",
      "No. 140 (test) -- acc: 0.2202\n",
      "No. 160 (test) -- acc: 0.2615\n",
      "No. 180 (test) -- acc: 0.2844\n",
      "No. 200 (test) -- acc: 0.3119\n",
      "No. 218 (test) -- acc: 0.3349\n",
      "Final accuracy: 0.3349, mean avg precision 0.2251, f1: 0.2560\n"
     ]
    }
   ],
   "source": [
    "# load model for testing\n",
    "model = ConvNet()\n",
    "model.load_state_dict(torch.load(\"trained_models/net_weighted.pt\"))\n",
    "# test model\n",
    "test(model.double(), test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation, no weighted loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 20 (test) -- acc: 0.0550\n",
      "No. 40 (test) -- acc: 0.0872\n",
      "No. 60 (test) -- acc: 0.1193\n",
      "No. 80 (test) -- acc: 0.1422\n",
      "No. 100 (test) -- acc: 0.1606\n",
      "No. 120 (test) -- acc: 0.1927\n",
      "No. 140 (test) -- acc: 0.2202\n",
      "No. 160 (test) -- acc: 0.2569\n",
      "No. 180 (test) -- acc: 0.2706\n",
      "No. 200 (test) -- acc: 0.3028\n",
      "No. 218 (test) -- acc: 0.3303\n",
      "Final accuracy: 0.3303, mean avg precision 0.2083, f1: 0.2946\n"
     ]
    }
   ],
   "source": [
    "# load model for testing\n",
    "model = ConvNet()\n",
    "model.load_state_dict(torch.load(\"trained_models/net_aug.pt\"))\n",
    "# test model\n",
    "test(model.double(), test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation, Weighted loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. 20 (test) -- acc: 0.0229\n",
      "No. 40 (test) -- acc: 0.0550\n",
      "No. 60 (test) -- acc: 0.0963\n",
      "No. 80 (test) -- acc: 0.1055\n",
      "No. 100 (test) -- acc: 0.1330\n",
      "No. 120 (test) -- acc: 0.1789\n",
      "No. 140 (test) -- acc: 0.2064\n",
      "No. 160 (test) -- acc: 0.2294\n",
      "No. 180 (test) -- acc: 0.2569\n",
      "No. 200 (test) -- acc: 0.2936\n",
      "No. 218 (test) -- acc: 0.3303\n",
      "Final accuracy: 0.3303, mean avg precision 0.2303, f1: 0.3154\n"
     ]
    }
   ],
   "source": [
    "# load model for testing\n",
    "model = ConvNet()\n",
    "model.load_state_dict(torch.load(\"trained_models/net_aug_weighted.pt\"))\n",
    "# test model\n",
    "test(model.double(), test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e85ec9bf098c5427e45e2f632dcd4eeff803b007e1abd287d600879388709c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
